# AI Learning Repository

Welcome to the AI Learning Repository. This repository contains code and theoretical concepts aimed at helping you understand various aspects of artificial intelligence, particularly LangChain, agents, and large language models (LLMs). 

## Table of Contents

1. [Introduction](#introduction)
2. [LangChain](#langchain)
3. [Agents](#agents)
   - [Components of Agents](#components-of-agents)
     - [Brain](#brain)
     - [Perception](#perception)
     - [Action](#action)
4. [LLMs](#llms)
5. [Streamlit](#streamlit)
6. [Hugging Face](#hugging-face)
7. [Problem Statement](#problem-statement)
8. [Our Solution](#our-solution)
9. [Running the Code](#running-the-code)
10. [Contributing](#contributing)
11. [License](#license)

## Introduction

This repository is designed to help you get started with AI concepts and tools. It includes a practical example of using LangChain for image captioning and object detection, along with theoretical insights into agents and LLMs.

## LangChain

LangChain is a framework for developing applications powered by language models. It simplifies the creation of chatbots, virtual agents, and other AI-driven tools.

## Agents

An agent is a computational entity that is aware of its environment and can perceive and act upon it to achieve specific goals.

### Components of Agents

Agents are composed of three main components:

#### Brain

The Brain component handles reasoning, planning, and decision-making. It uses memory to store past interactions and knowledge to inform future actions.

- **Memory Module**: Stores past interactions and historical data, enabling the agent to plan and take actions based on previous experiences.
- **Profiler Module**: Adapts the agent's behavior to the user's profile.
- **Knowledge Base**: A repository of accumulated knowledge and competencies.

#### Perception

The Perception component processes information generated by humans or other agents. It can handle various types of data, such as text, audio, and images.

- **Functionality**: This component processes information generated by humans or other agents. It can analyze textual, visual, and auditory information to understand the environment.
- **Examples**: Analyzing text input from users, recognizing objects in images, or understanding spoken language.

#### Action

The Action component allows the agent to interact with its environment and other systems. It includes modules for generating responses and executing tasks.

- **Functionality**: Enables the agent to respond to its environment and execute tasks. It includes modules for generating responses and interacting with other systems.
- **Steps and Phases**: Using the processes of the Brain component, the agent can decompose tasks into manageable steps and phases, using appropriate tools for each task.

### Characteristics of Agents

- **Autonomous and Independent**: Agents act and make decisions driven by defined objectives without human intervention.
- **Instructions and Tools**: Agents use instructions and tools to achieve their goals. They plan and reason independently.
- **Interactivity**: Agents communicate with other agents or humans, simulating social behaviors and interactions.

## LLMs

Large Language Models (LLMs) are powerful models trained on vast amounts of data. They can understand and generate human language, making them useful for a variety of applications, such as chatbots, text summarization, and more.

## Streamlit

Streamlit is an open-source Python framework that allows data scientists and AI/ML engineers to create and share data-driven web applications quickly and easily. Streamlit apps are written entirely in Python, requiring no front-end development experience. The framework simplifies the process of building interactive data apps and allows users to focus on functionality rather than design.

Key features of Streamlit include:

- **Ease of Use**: Streamlit turns Python scripts into interactive web apps in just a few minutes.
- **Interactivity**: The framework includes various widgets and components that allow for dynamic and responsive applications.
- **Integration**: Streamlit can be easily integrated with data science and machine learning workflows, enabling real-time data visualization and model interaction.

Streamlit's popularity stems from its simplicity and the ability to create powerful data applications without extensive web development knowledge.

## Hugging Face

Hugging Face is a company that has created a comprehensive ecosystem for natural language processing (NLP) and machine learning. It is widely known for its Transformers library, which provides easy access to pre-trained models and tools for NLP tasks.

### Why Hugging Face is Popular

- **Transformers Library**: This library offers APIs and tools for downloading and using pre-trained models for various NLP tasks such as text classification, translation, summarization, and more.
- **Community and Open Source**: Hugging Face has fostered a large, active community contributing to its open-source projects, enhancing their capabilities and expanding their applications.
- **Ease of Use**: The library simplifies complex NLP tasks, making state-of-the-art models accessible to both researchers and developers.

### Key Features of the Transformers Library

- **Pre-trained Models**: Access to thousands of pre-trained models that can be used directly or fine-tuned for specific tasks.
- **APIs and Tools**: Comprehensive APIs for model deployment and inference, supporting a variety of tasks like question answering, named entity recognition, and language generation.
- **Integration**: The library is designed to work seamlessly with other popular machine learning frameworks such as PyTorch and TensorFlow.

Hugging Face's Transformers library has become a cornerstone for many NLP applications due to its extensive model repository and ease of integration into various machine learning workflows.

## Problem Statement

### About CRDN

CRDN (Certified Restoration Drycleaning Network) is a leading expert in textile and electronic restoration. They serve as part of the emergency response team, working with policyholders, insurance representatives, and contractors to restore textiles, electronics, art, and peace of mind after a disaster such as a fire, flood, or storm. CRDNâ€™s services help reduce replacement costs and limit additional living expenses for their clients.

### The Problem

Currently, CRDN employs individuals to manually identify and categorize images sent by clients. These images typically fall into one of three categories:

- **Textile Restoration**: Items like clothing, linens, and other fabrics.
- **Electronic Restoration**: Devices such as laptops, phones, and home appliances.
- **Art Restoration**: Artworks including paintings, sculptures, and collectibles.

The manual process of categorizing these items is time-consuming and prone to human error. As CRDN deals with numerous claims, the need for an efficient, automated system to handle this task has become apparent.

## Our Solution

We propose developing an AI-driven software system that automates the image categorization process. This solution utilizes agents that incorporate Large Language Models (LLMs) to interpret and classify images accurately. The proposed system includes the following components:

1. **Agent Initialization**: We initialize an agent using the LangChain framework. This agent will leverage various tools designed for image processing tasks.
   
2. **Tools for Image Processing**: 
    - **ImageCaptionTool**: This tool generates captions for the provided images using a pre-trained BLIP (Bootstrapping Language-Image Pre-training) model. The captions help in understanding the content of the images. You can explore more about this model on [Hugging Face](https://huggingface.co/Salesforce/blip-image-captioning-large). On the Hugging Face page, you will find an Inference API section that allows you to use the API to see if it meets your requirements, and in the "How to use" section, you can see how to use it with the Transformers library.
    - **ObjectDetectionTool**: This tool detects objects in the provided images using a pre-trained DETR (DEtection TRansformers) model. It identifies and classifies objects within the images into the specified categories: Textile, Electronic, and Art restoration. You can explore more about this model on [Hugging Face](https://huggingface.co/facebook/detr-resnet-50). On the Hugging Face page, you will find an Inference API section that allows you to use the API to see if it meets your requirements, and in the "How to use" section, you can see how to use it with the Transformers library. After testing the object detection model from [Hugging Face](https://huggingface.co/facebook/detr-resnet-50), we realized that it did not meet our needs as it was too imprecise for our use case. Therefore, we decided to use only the ImageCaptionTool for our agent.

3. **Image Processing Helper**: A helper class that provides improved logic for classifying objects into restoration categories based on the captions and detected objects.

4. **Memory Management**: The agent utilizes a conversational memory (ConversationBufferWindowMemory) to store the chat history and past interactions, ensuring context-awareness in the decision-making process.

5. **Model Integration**: The agent uses the ChatOpenAI model (specifically GPT-4) to process the image captions and detected objects, and to generate a detailed classification of the objects.

### Detailed Workflow

- **Image Upload**: Users upload an image through a Streamlit interface.
- **Caption Generation**: The ImageCaptionTool generates a caption for the uploaded image.
- **Object Detection**: The ObjectDetectionTool detects and classifies objects in the image.
- **Classification and Confidence Score**: The system categorizes the detected objects into Textile, Electronic, or Art restoration categories, and assigns a confidence score. If the confidence score is below a threshold, an alert for human validation is raised.
- **Output Display**: The classified objects, categories, and confidence scores are displayed to the user through the Streamlit interface.

This AI-driven solution will significantly reduce the time and effort required to process claims, enhance accuracy, and allow CRDN staff to focus on more complex tasks.

## Running the Code

To run the code in this repository, follow these steps:

1. Clone the repository:
    ```bash
    git clone https://github.com/your-repo-url
    cd your-repo-directory
    ```

2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

3. Set up environment variables by creating a `.env` file:
    ```
    OPENAI_API_KEY=your_openai_api_key
    ```

4. Run the main script:
    ```bash
    streamlit run main.py
    ```

This will start a Streamlit application where you can upload an image and interact with the AI agent.

## Contributing

We welcome contributions to this repository. If you have any improvements or suggestions, please create
